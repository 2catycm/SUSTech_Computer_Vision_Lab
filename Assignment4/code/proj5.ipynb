{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection with a Sliding Window\n",
    "1. Extract features for positive examples\n",
    "2. Extract features for random negative examples\n",
    "3. Mine hard negatives\n",
    "4. Train a linear classifier\n",
    "5. Detect faces on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "# %matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "import student_code as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = osp.join('..','data')\n",
    "# Positive training examples. 36x36 head crops\n",
    "train_path_pos = osp.join(data_path, 'caltech_faces', 'Caltech_CropFaces')\n",
    "# Mine random or hard negatives from here\n",
    "non_face_scn_path = osp.join(data_path, 'train_non_face_scenes')\n",
    "# CMU+MIT test scenes\n",
    "test_scn_path = osp.join(data_path, 'test_scenes', 'test_jpg')\n",
    "# Ground truth face locations in the test set\n",
    "label_filename = osp.join(data_path, 'test_scenes', 'ground_truth_bboxes.txt')\n",
    "\n",
    "# The faces are 36x36 pixels, which works fine as a template size. You could\n",
    "# add other fields to this dict if you want to modify HoG default\n",
    "# parameters such as the number of orientations, but that does not help\n",
    "# performance in our limited test.\n",
    "feature_params = {'template_size': 36, 'hog_cell_size': 6}\n",
    "\n",
    "# Number of negatives to use for training.\n",
    "# Higher will work strictly better, but you should start with 10000 for debugging\n",
    "num_negative_examples = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Load positive training crops and random negative examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydev_jupyter_utils'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-20-a670e9bf3773>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0msys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minsert\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'C:\\\\Users\\\\YeCanming\\\\AppData\\\\Local\\\\JetBrains\\\\Toolbox\\\\apps\\\\PyCharm-P\\\\ch-0\\\\222.4459.20\\\\plugins\\\\python\\\\helpers\\\\pydev'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0msys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minsert\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'C:\\\\Users\\\\YeCanming\\\\AppData\\\\Local\\\\JetBrains\\\\Toolbox\\\\apps\\\\PyCharm-P\\\\ch-0\\\\222.4459.20\\\\plugins\\\\python\\\\helpers-pro\\\\jupyter_debug'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mpydev_jupyter_utils\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mremove_imported_pydev_package\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m \u001B[0mremove_imported_pydev_package\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpydev_jupyter_utils\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'pydev_jupyter_utils'"
     ]
    }
   ],
   "source": [
    "features_pos = sc.get_positive_features(train_path_pos, feature_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13426, 1116)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_pos[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_neg = sc.get_random_negative_features(non_face_scn_path, feature_params,\n",
    "                                               num_negative_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Train Classifier\n",
    "Use [scikit-learn LinearSVC](http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC) to on your training features to learn a linear classifier. The regularization constant C is an important parameter, try many values. Small values seem to work better (e.g. 1e-4), but you can try other values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svm = sc.train_classifier(features_pos, features_neg, 5e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Examine Learned Classifier\n",
    "You don't need to modify anything in this section. The section first\n",
    "evaluates _training_ error, which isn't ultimately what we care about,\n",
    "but it's a good sanity check. Your training error should be very low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 98.000%\n",
      "True Positive rate = 100.000%\n",
      "False Positive rate = 100.000%\n",
      "True Negative rate = 0.000%\n",
      "False Negative rate = 0.000%\n"
     ]
    }
   ],
   "source": [
    "confidences = svm.decision_function(np.vstack((features_pos, features_neg)))\n",
    "label_vector = np.hstack((np.ones(len(features_pos)), -np.ones(len(features_neg))))\n",
    "[tp_rate, fp_rate, tn_rate, fn_rate] = report_accuracy(confidences, label_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize how well separated the positive and negative examples are at\n",
    "training time. Sometimes this can idenfity odd biases in your training\n",
    "data, especially if you're trying hard negative mining. This\n",
    "visualization won't be very meaningful with the placeholder starter code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Unknown property density",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-10-bc3067299f1a>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mnon_face_confs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconfidences\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mlabel_vector\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfigure\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msort\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mface_confs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m100\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfacecolor\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'g'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhisttype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'step'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdensity\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mlabel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'faces'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msort\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnon_face_confs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m100\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfacecolor\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'r'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhisttype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'step'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdensity\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'non faces'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;31m#plt.plot([0, len(non_face_confs)], [0, 0], 'b', label='decision boundary')\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/a3env/lib/python3.6/site-packages/matplotlib/pyplot.py\u001B[0m in \u001B[0;36mhist\u001B[0;34m(x, bins, range, normed, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, hold, data, **kwargs)\u001B[0m\n\u001B[1;32m   3079\u001B[0m                       \u001B[0mhisttype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mhisttype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0malign\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0malign\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morientation\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0morientation\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3080\u001B[0m                       \u001B[0mrwidth\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrwidth\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlog\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlog\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcolor\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcolor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlabel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3081\u001B[0;31m                       stacked=stacked, data=data, **kwargs)\n\u001B[0m\u001B[1;32m   3082\u001B[0m     \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3083\u001B[0m         \u001B[0max\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_hold\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mwashold\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/a3env/lib/python3.6/site-packages/matplotlib/__init__.py\u001B[0m in \u001B[0;36minner\u001B[0;34m(ax, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1896\u001B[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001B[1;32m   1897\u001B[0m                                   RuntimeWarning, stacklevel=2)\n\u001B[0;32m-> 1898\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0max\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1899\u001B[0m         \u001B[0mpre_doc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minner\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__doc__\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1900\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mpre_doc\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/a3env/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001B[0m in \u001B[0;36mhist\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m   6387\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mpatch\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6388\u001B[0m                 \u001B[0mp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpatch\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 6389\u001B[0;31m                 \u001B[0mp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   6390\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mlbl\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6391\u001B[0m                     \u001B[0mp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_label\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlbl\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/a3env/lib/python3.6/site-packages/matplotlib/artist.py\u001B[0m in \u001B[0;36mupdate\u001B[0;34m(self, props)\u001B[0m\n\u001B[1;32m    883\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    884\u001B[0m             ret = [_update_property(self, k, v)\n\u001B[0;32m--> 885\u001B[0;31m                    for k, v in props.items()]\n\u001B[0m\u001B[1;32m    886\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    887\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meventson\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstore\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/a3env/lib/python3.6/site-packages/matplotlib/artist.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    883\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    884\u001B[0m             ret = [_update_property(self, k, v)\n\u001B[0;32m--> 885\u001B[0;31m                    for k, v in props.items()]\n\u001B[0m\u001B[1;32m    886\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    887\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meventson\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstore\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/a3env/lib/python3.6/site-packages/matplotlib/artist.py\u001B[0m in \u001B[0;36m_update_property\u001B[0;34m(self, k, v)\u001B[0m\n\u001B[1;32m    876\u001B[0m                 \u001B[0mfunc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'set_'\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    877\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mfunc\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0msix\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcallable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 878\u001B[0;31m                     \u001B[0;32mraise\u001B[0m \u001B[0mAttributeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Unknown property %s'\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    879\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mv\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    880\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: Unknown property density"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f05b92e2c18>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "face_confs = confidences[label_vector > 0]\n",
    "non_face_confs = confidences[label_vector < 0]\n",
    "plt.figure()\n",
    "plt.hist(np.sort(face_confs), 100, facecolor='g', histtype='step', density=1,label='faces')\n",
    "plt.hist(np.sort(non_face_confs), 100, facecolor='r', histtype='step',density=1, label='non faces')\n",
    "#plt.plot([0, len(non_face_confs)], [0, 0], 'b', label='decision boundary')\n",
    "plt.xlabel('predicted score')\n",
    "plt.ylabel('Percentage of images')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the HOG feature template to examine if the detector has learned a meaningful representation for the object (faces in this case).  This would be a good thing to include in your writeup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_hog(svm, feature_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Mine Hard Negatives\n",
    "You can get very good performance by using random negatives, so hard negative mining may not show great improvement for face detection. Hard negative mining would probably be more important if you had a strict budget of negative training examples or a\n",
    "more expressive, non-linear classifier that can benefit from more training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hard_negs = sc.mine_hard_negs(non_face_scn_path, svm, feature_params)\n",
    "features_neg_2 = np.vstack((features_neg, hard_negs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can train the classifier again with the new features_neg. You can also check the difference of the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_2 = sc.train_classifier(features_pos, features_neg_2, 5e-2)\n",
    "\n",
    "confidences_2 = svm_2.decision_function(np.vstack((features_pos, features_neg)))\n",
    "[tp_rate, fp_rate, tn_rate, fn_rate] = report_accuracy(confidences_2, label_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Run Detector on Test Set\n",
    "Make sure the outputs of sc.run_detector() are properly structured! They will be interpreted in Section 6 to evaluate and visualize your\n",
    "results. See sc.run_detector() documentation for more details.\n",
    "\n",
    "sc.run_detector() will have (at least) two parameters which can heavily\n",
    "influence performance - how much to rescale each step of your multiscale\n",
    "detector, and the threshold for a detection. If your recall rate is low\n",
    "and your detector still has high precision at its highest recall point,\n",
    "you can improve your average precision by reducing the threshold for a\n",
    "positive detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bboxes, confidences, image_ids = sc.run_detector(test_scn_path, svm, feature_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's detect again using the classifier trained using hard negative examples. The results will be saved separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes_2, confidences_2, image_ids_2 = sc.run_detector(test_scn_path, svm_2, feature_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Evaluate and Visualize Detections\n",
    "These functions require ground truth annotations, and thus can only be run on the CMU+MIT face test set. \n",
    "Don't modify anything in evaluate_detections()!\n",
    "\n",
    "Performance to aim for:\n",
    "- random (stater code): 0.001 AP\n",
    "- single scale: ~ 0.3 to 0.4 AP\n",
    "- multiscale: ~ 0.8 to 0.9 AP\n",
    "\n",
    "You need to implement multi-scale detection and achieve at least 0.8 AP to receive the full credit.\n",
    "\n",
    "First we compare the detection performance between different classifiers quantitatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gt_ids, gt_bboxes, gt_isclaimed, tp, fp, duplicate_detections = evaluate_detections(bboxes, confidences,\n",
    "                                                                                    image_ids, label_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gt_ids, gt_bboxes, gt_isclaimed, tp_2, fp_2, duplicate_detections_2 = evaluate_detections(bboxes_2, confidences_2,\n",
    "                                                                                    image_ids_2, label_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we show the detection results on the test scenes. By default we only show the results from the second classifier. You can also check the first classifier by uncommenting the first line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualize_detections_by_image(bboxes, confidences, image_ids, tp, fp, test_scn_path, label_filename)\n",
    "visualize_detections_by_image(bboxes_2, confidences_2, image_ids_2, tp_2, fp_2, test_scn_path, label_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a3env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2 |Continuum Analytics, Inc.| (default, Jul 20 2017, 13:51:32) \n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "3193c0413268bbb59f9d23a695be3cc9adb742d69b2610f1f53504f916cfbbd6"
   }
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
