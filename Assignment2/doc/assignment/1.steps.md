

> **Interest point detection** (SID\<studentID\>\_harris.py)
>
> You will implement the Harris corner detector as described in the
> lecture materials and Szeliski 4.1.1. See Algorithm 4.1 in the
> textbook for pseudocode. The starter code gives some additional
> suggestions. You do not need to worry about scale invariance or
> key-point orientation estimation for your baseline Harris corner
> detector. The original paper by Chris Harris and Mike Stephens
> describing their corner detector can be found here.
>
> You will also implement **adaptive non-maximal suppression.** While
> most feature detectors simply look for local maxima in the interest
> function, this can lead to an uneven distribution of feature points
> across the image, e.g., points will be denser in regions of higher
> contrast. To mitigate this problem, Brown, Szeliski, and Winder (2005)
> only detect features that are both local maxima and whose response
> value is significantly (10%) greater than that of all of its neighbors
> within a radius r. The goal is to retain only those points that are a
> maximum in a neighborhood of radius r pixels. One way to do so is to
> sort all points by the response strength, from large to small
> response. The first entry in the list is the global maximum, which is
> not suppressed at any radius. Then, we can iterate through the list
> and compute the distance to each interest point ahead of it in the
> list (these are pixels with even greater response strength). The
> minimum of distances to a key-point\'s stronger neighbors (multiplying
> these neighbors by \>=1.1 to add robustness) is the radius within
> which the current point is a local maximum. We call this the
> suppression radius of this interest point, and we save these
> suppression radii. Finally, we sort the suppression radii from large
> to small, and return the n key-points associated with the top n
> suppression radii, in this sorted order. Feel free to experiment with
> n, we used n=1500.
>
> **Local feature description** (SID\<studentID\>\_sift.py)
>
> You will implement a SIFT-like local feature as described in the
> lecture materials and Szeliski 4.1.2. See the placeholder
> get_features() for more details. If you want to get your matching
> pipeline working quickly (and maybe to help debug the other algorithm
> stages), you might want to start with normalized patches as your local
> feature.
>
> **Feature matching** (SID\<studentID\>\_sift.py)
>
> You will implement the \"ratio test\" or \"nearest neighbor distance
> ratio test\" method of matching local features as described in the
> lecture materials and Szeliski 4.1.3. See equation 4.18 in particular.
> The potential matches that pass the ratio test the easiest should have
> a greater tendency to be correct matches \-- think about *why*.



